{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c855a4",
   "metadata": {},
   "source": [
    "# Peer Project...Team Akatsuki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2252b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "file_path = r\"D:\\Buildables Internship\\CyberBullying\\data\\cyberbullying_tweets.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6657c54",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "    @peers update the file path if you have csv in anyother folder or etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f0c9038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully from: D:\\Buildables Internship\\CyberBullying\\data\\cyberbullying_tweets.csv\n",
      "Original DataFrame head:\n",
      "                                          tweet_text cyberbullying_type\n",
      "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
      "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
      "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
      "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
      "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n"
     ]
    }
   ],
   "source": [
    "# --- Load the dataset ---\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Dataset loaded successfully from: {file_path}\")\n",
    "    print(\"Original DataFrame head:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please ensure it's in the correct directory.\")\n",
    "    # Exit or handle the error appropriately if the file is not found\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704af5c3",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d30abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying cleaning steps...\n"
     ]
    }
   ],
   "source": [
    "# --- Data Cleaning Steps ---\n",
    "# Create a new column for cleaned text to preserve the original\n",
    "df['cleaned_tweet_text'] = df['tweet_text']\n",
    "print(\"\\nApplying cleaning steps...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64349a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: URLs removed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Remove URLs\n",
    "# Regex to find http, https, or www links\n",
    "df['cleaned_tweet_text'] = df['cleaned_tweet_text'].apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+', '', x, flags=re.MULTILINE))\n",
    "print(\"Step 1: URLs removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5be9bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Mentions removed.\n"
     ]
    }
   ],
   "source": [
    "# 2. Remove mentions (@username)\n",
    "# Regex to find words starting with @\n",
    "df['cleaned_tweet_text'] = df['cleaned_tweet_text'].apply(lambda x: re.sub(r'@\\w+', '', x))\n",
    "print(\"Step 2: Mentions removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d294ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Hashtag symbols removed.\n"
     ]
    }
   ],
   "source": [
    "# 3. Remove hashtag symbols (#) but keep the text\n",
    "# Regex to find # symbol\n",
    "df['cleaned_tweet_text'] = df['cleaned_tweet_text'].apply(lambda x: re.sub(r'#', '', x))\n",
    "print(\"Step 3: Hashtag symbols removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf5967e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Special characters and numbers removed.\n"
     ]
    }
   ],
   "source": [
    "# 4. Remove special characters and numbers, keep only letters and spaces\n",
    "# Regex to find anything that is NOT a letter or whitespace\n",
    "df['cleaned_tweet_text'] = df['cleaned_tweet_text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "print(\"Step 4: Special characters and numbers removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4570cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Extra whitespace removed.\n"
     ]
    }
   ],
   "source": [
    "# 5. Remove extra whitespace (multiple spaces, leading/trailing spaces)\n",
    "# Regex to find one or more whitespace characters\n",
    "df['cleaned_tweet_text'] = df['cleaned_tweet_text'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "print(\"Step 5: Extra whitespace removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e50c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Text converted to lowercase.\n"
     ]
    }
   ],
   "source": [
    "# 6. Convert text to lowercase\n",
    "df['cleaned_tweet_text'] = df['cleaned_tweet_text'].apply(lambda x: x.lower())\n",
    "print(\"Step 6: Text converted to lowercase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0abf3a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data cleaning complete. Here are the first few rows of the cleaned data:\n",
      "                                          tweet_text  \\\n",
      "0  In other words #katandandre, your food was cra...   \n",
      "1  Why is #aussietv so white? #MKR #theblock #ImA...   \n",
      "2  @XochitlSuckkks a classy whore? Or more red ve...   \n",
      "3  @Jason_Gio meh. :P  thanks for the heads up, b...   \n",
      "4  @RudhoeEnglish This is an ISIS account pretend...   \n",
      "\n",
      "                                  cleaned_tweet_text cyberbullying_type  \n",
      "0  in other words katandandre your food was crapi...  not_cyberbullying  \n",
      "1  why is aussietv so white mkr theblock imaceleb...  not_cyberbullying  \n",
      "2         a classy whore or more red velvet cupcakes  not_cyberbullying  \n",
      "3  meh p thanks for the heads up but not too conc...  not_cyberbullying  \n",
      "4  this is an isis account pretending to be a kur...  not_cyberbullying  \n"
     ]
    }
   ],
   "source": [
    "# --- Display the cleaned data ---\n",
    "print(\"\\nData cleaning complete. Here are the first few rows of the cleaned data:\")\n",
    "print(df[['tweet_text', 'cleaned_tweet_text', 'cyberbullying_type']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44e9fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data saved to 'D:\\Buildables Internship\\CyberBullying\\data\\cyberbullying_tweets_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "#Save the cleaned DataFrame ---\n",
    "output_file_path = r\"D:\\Buildables Internship\\CyberBullying\\data\\cyberbullying_tweets_cleaned.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"\\nCleaned data saved to '{output_file_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
